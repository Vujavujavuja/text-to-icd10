{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICD-10 Dataset Preprocessing\n",
    "\n",
    "This notebook generates pre-computed artifacts for the ICD-10 Coding Assistant:\n",
    "\n",
    "1. Download ICD-10 dataset from Hugging Face\n",
    "2. Apply chapter enrichment using mapping logic\n",
    "3. Generate synonym variations from descriptions\n",
    "4. Generate embeddings for all descriptions\n",
    "5. Build FAISS index\n",
    "6. Save artifacts to `data/cache/`\n",
    "\n",
    "**Expected runtime:** 2-3 minutes (one-time)\n",
    "\n",
    "**Output artifacts:**\n",
    "- `data/cache/enriched_dataset.pkl` - DataFrame with code/description/chapter/synonyms\n",
    "- `data/cache/icd10_index.faiss` - Pre-built FAISS index\n",
    "- `data/cache/metadata.json` - Dataset metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path to import app utilities\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import utilities from app\n",
    "from app.utils.chapter_mapping import get_chapter_from_code\n",
    "from app.utils.code_formatter import CodeFormatter\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ICD-10 dataset from Hugging Face...\n",
      "Loaded 72750 ICD-10 codes\n",
      "\n",
      "Original columns: ['Code', 'Description']\n",
      "Renamed columns: ['code', 'description']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A001</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A009</td>\n",
       "      <td>Cholera, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0100</td>\n",
       "      <td>Typhoid fever, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0101</td>\n",
       "      <td>Typhoid meningitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                                        description\n",
       "0   A000  Cholera due to Vibrio cholerae 01, biovar chol...\n",
       "1   A001    Cholera due to Vibrio cholerae 01, biovar eltor\n",
       "2   A009                               Cholera, unspecified\n",
       "3  A0100                         Typhoid fever, unspecified\n",
       "4  A0101                                 Typhoid meningitis"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading ICD-10 dataset from Hugging Face...\")\n",
    "dataset = load_dataset(\"awacke1/ICD10-Clinical-Terminology\")\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "print(f\"Loaded {len(df)} ICD-10 codes\")\n",
    "print(f\"\\nOriginal columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Rename columns to lowercase for consistency\n",
    "df.columns = df.columns.str.lower()\n",
    "print(f\"Renamed columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "code           0\n",
      "description    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "code           str\n",
      "description    str\n",
      "dtype: object\n",
      "\n",
      "Sample codes:\n",
      "['A000', 'A001', 'A009', 'A0100', 'A0101', 'A0102', 'A0103', 'A0104', 'A0105', 'A0109']\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Sample codes\n",
    "print(\"\\nSample codes:\")\n",
    "print(df['code'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chapter Enrichment\n",
    "\n",
    "Apply ICD-10 chapter mapping to all codes using the chapter_mapping utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying chapter enrichment...\n",
      "Chapter enrichment complete\n",
      "\n",
      "Chapter distribution:\n",
      "chapter\n",
      "XIX. Injury, poisoning and certain other consequences of external causes      40786\n",
      "XX. External causes of morbidity                                               7067\n",
      "XIII. Diseases of the musculoskeletal system and connective tissue             6563\n",
      "VII. Diseases of the eye and adnexa                                            2628\n",
      "XV. Pregnancy, childbirth and the puerperium                                   2271\n",
      "II. Neoplasms                                                                  1642\n",
      "IX. Diseases of the circulatory system                                         1379\n",
      "XXI. Factors influencing health status and contact with health services        1289\n",
      "I. Certain infectious and parasitic diseases                                   1064\n",
      "IV. Endocrine, nutritional and metabolic diseases                               913\n",
      "XII. Diseases of the skin and subcutaneous tissue                               879\n",
      "XVII. Congenital malformations, deformations and chromosomal abnormalities      837\n",
      "XI. Diseases of the digestive system                                            817\n",
      "V. Mental, Behavioral and Neurodevelopmental disorders                          770\n",
      "XVIII. Symptoms, signs and abnormal clinical and laboratory findings            735\n",
      "XIV. Diseases of the genitourinary system                                       686\n",
      "VIII. Diseases of the ear and mastoid process                                   653\n",
      "VI. Diseases of the nervous system                                              650\n",
      "XVI. Certain conditions originating in the perinatal period                     455\n",
      "X. Diseases of the respiratory system                                           346\n",
      "III. Diseases of the blood and blood-forming organs                             295\n",
      "Unknown                                                                          22\n",
      "XXII. Codes for special purposes                                                  3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample enriched data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A001</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A009</td>\n",
       "      <td>Cholera, unspecified</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0100</td>\n",
       "      <td>Typhoid fever, unspecified</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0101</td>\n",
       "      <td>Typhoid meningitis</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0102</td>\n",
       "      <td>Typhoid fever with heart involvement</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0103</td>\n",
       "      <td>Typhoid pneumonia</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0104</td>\n",
       "      <td>Typhoid arthritis</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0105</td>\n",
       "      <td>Typhoid osteomyelitis</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0109</td>\n",
       "      <td>Typhoid fever with other complications</td>\n",
       "      <td>I. Certain infectious and parasitic diseases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                                        description  \\\n",
       "0   A000  Cholera due to Vibrio cholerae 01, biovar chol...   \n",
       "1   A001    Cholera due to Vibrio cholerae 01, biovar eltor   \n",
       "2   A009                               Cholera, unspecified   \n",
       "3  A0100                         Typhoid fever, unspecified   \n",
       "4  A0101                                 Typhoid meningitis   \n",
       "5  A0102               Typhoid fever with heart involvement   \n",
       "6  A0103                                  Typhoid pneumonia   \n",
       "7  A0104                                  Typhoid arthritis   \n",
       "8  A0105                              Typhoid osteomyelitis   \n",
       "9  A0109             Typhoid fever with other complications   \n",
       "\n",
       "                                        chapter  \n",
       "0  I. Certain infectious and parasitic diseases  \n",
       "1  I. Certain infectious and parasitic diseases  \n",
       "2  I. Certain infectious and parasitic diseases  \n",
       "3  I. Certain infectious and parasitic diseases  \n",
       "4  I. Certain infectious and parasitic diseases  \n",
       "5  I. Certain infectious and parasitic diseases  \n",
       "6  I. Certain infectious and parasitic diseases  \n",
       "7  I. Certain infectious and parasitic diseases  \n",
       "8  I. Certain infectious and parasitic diseases  \n",
       "9  I. Certain infectious and parasitic diseases  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Applying chapter enrichment...\")\n",
    "\n",
    "# Apply chapter mapping to all codes\n",
    "df['chapter'] = df['code'].apply(get_chapter_from_code)\n",
    "\n",
    "print(f\"Chapter enrichment complete\")\n",
    "print(f\"\\nChapter distribution:\")\n",
    "print(df['chapter'].value_counts())\n",
    "\n",
    "# Show sample enriched rows\n",
    "print(\"\\nSample enriched data:\")\n",
    "df[['code', 'description', 'chapter']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Synonym Generation\n",
    "\n",
    "Generate simple synonym variations from descriptions.\n",
    "This can be enhanced later with NLP techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synonyms...\n",
      "Synonym generation complete\n",
      "\n",
      "Sample synonyms:\n"
     ]
    }
   ],
   "source": [
    "def generate_synonyms(description: str) -> list:\n",
    "    \"\"\"\n",
    "    Generate simple synonym variations from description.\n",
    "    \n",
    "    This is a basic implementation. Can be enhanced with:\n",
    "    - Medical terminology databases (UMLS, SNOMED CT)\n",
    "    - NLP-based synonym extraction\n",
    "    - Abbreviation expansion\n",
    "    \"\"\"\n",
    "    if not description or not isinstance(description, str):\n",
    "        return []\n",
    "    \n",
    "    synonyms = []\n",
    "    desc_lower = description.lower()\n",
    "    \n",
    "    # Common medical abbreviations and variations\n",
    "    replacements = [\n",
    "        ('type 2 diabetes mellitus', 'diabetes mellitus type 2'),\n",
    "        ('type 1 diabetes mellitus', 'diabetes mellitus type 1'),\n",
    "        ('diabetes mellitus', 'DM'),\n",
    "        ('myocardial infarction', 'MI'),\n",
    "        ('congestive heart failure', 'CHF'),\n",
    "        ('chronic obstructive pulmonary disease', 'COPD'),\n",
    "        ('hypertension', 'high blood pressure'),\n",
    "    ]\n",
    "    \n",
    "    for original, replacement in replacements:\n",
    "        if original in desc_lower:\n",
    "            synonym = description.replace(original, replacement)\n",
    "            if synonym != description:\n",
    "                synonyms.append(synonym)\n",
    "    \n",
    "    # Limit to 3 synonyms to keep data size manageable\n",
    "    return synonyms[:3]\n",
    "\n",
    "print(\"Generating synonyms...\")\n",
    "df['synonyms'] = df['description'].apply(generate_synonyms)\n",
    "\n",
    "print(f\"Synonym generation complete\")\n",
    "print(f\"\\nSample synonyms:\")\n",
    "for idx in range(min(5, len(df))):\n",
    "    if df.iloc[idx]['synonyms']:\n",
    "        print(f\"\\nCode: {df.iloc[idx]['code']}\")\n",
    "        print(f\"Description: {df.iloc[idx]['description']}\")\n",
    "        print(f\"Synonyms: {df.iloc[idx]['synonyms']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Embeddings\n",
    "\n",
    "Generate embeddings for all descriptions using sentence-transformers.\n",
    "This is the most time-consuming step (60-90 seconds for 72k codes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef4a30fb9544597a62d5814b3ab1625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "\n",
      "Generating embeddings for 72750 descriptions...\n",
      "This may take 60-90 seconds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c393ad40e0d466f839fca20e5fc1a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated embeddings: (72750, 384)\n",
      "Embedding dimension: 384\n",
      "Total vectors: 72750\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "print(f\"Loading embedding model: {model_name}\")\n",
    "model = SentenceTransformer(model_name)\n",
    "print(f\"Model loaded\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(f\"\\nGenerating embeddings for {len(df)} descriptions...\")\n",
    "print(\"This may take 60-90 seconds...\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    df['description'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated embeddings: {embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"Total vectors: {embeddings.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build FAISS Index\n",
    "\n",
    "Build FAISS index for fast similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index...\n",
      "FAISS index built: 72750 vectors\n",
      "Index type: IndexFlatL2 (exact search)\n",
      "Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "print(\"Building FAISS index...\")\n",
    "\n",
    "# Create FAISS index (IndexFlatL2 for exact search)\n",
    "dimension = embeddings.shape[1]  # 384 for all-MiniLM-L6-v2\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings.astype('float32'))\n",
    "\n",
    "print(f\"FAISS index built: {index.ntotal} vectors\")\n",
    "print(f\"Index type: IndexFlatL2 (exact search)\")\n",
    "print(f\"Dimension: {dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Artifacts\n",
    "\n",
    "Save all pre-computed artifacts to `data/cache/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifacts to ../data/cache/...\n",
      "Saved enriched dataset: ../data/cache\\enriched_dataset.pkl (11.7 MB)\n",
      "Saved FAISS index: ../data/cache\\icd10_index.faiss (106.6 MB)\n",
      "Saved metadata: ../data/cache\\metadata.json\n",
      "\n",
      "============================================================\n",
      "ALL ARTIFACTS SAVED SUCCESSFULLY!\n",
      "============================================================\n",
      "\n",
      "Total artifacts size: 118.3 MB\n",
      "\n",
      "You can now start the FastAPI server with:\n",
      "  uvicorn app.main:app --reload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nemanja.vujic\\AppData\\Local\\Temp\\ipykernel_56004\\1693307961.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  'created_at': datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "# Create cache directory\n",
    "cache_dir = '../data/cache'\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving artifacts to {cache_dir}/...\")\n",
    "\n",
    "# 1. Save enriched dataset\n",
    "pkl_path = os.path.join(cache_dir, 'enriched_dataset.pkl')\n",
    "df.to_pickle(pkl_path)\n",
    "pkl_size_mb = os.path.getsize(pkl_path) / (1024 * 1024)\n",
    "print(f\"Saved enriched dataset: {pkl_path} ({pkl_size_mb:.1f} MB)\")\n",
    "\n",
    "# 2. Save FAISS index\n",
    "index_path = os.path.join(cache_dir, 'icd10_index.faiss')\n",
    "faiss.write_index(index, index_path)\n",
    "index_size_mb = os.path.getsize(index_path) / (1024 * 1024)\n",
    "print(f\"Saved FAISS index: {index_path} ({index_size_mb:.1f} MB)\")\n",
    "\n",
    "# 3. Save metadata\n",
    "metadata = {\n",
    "    'version': '1.0',\n",
    "    'dataset': 'awacke1/ICD10-Clinical-Terminology',\n",
    "    'row_count': len(df),\n",
    "    'embedding_model': model_name,\n",
    "    'embedding_dimension': dimension,\n",
    "    'created_at': datetime.utcnow().isoformat(),\n",
    "    'chapter_count': df['chapter'].nunique()\n",
    "}\n",
    "\n",
    "meta_path = os.path.join(cache_dir, 'metadata.json')\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Saved metadata: {meta_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL ARTIFACTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal artifacts size: {pkl_size_mb + index_size_mb:.1f} MB\")\n",
    "print(f\"\\nYou can now start the FastAPI server with:\")\n",
    "print(f\"  uvicorn app.main:app --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verification\n",
    "\n",
    "Verify that artifacts can be loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying artifacts...\n",
      "Loaded dataset: 72750 rows\n",
      "Loaded FAISS index: 72750 vectors\n",
      "Loaded metadata: version 1.0\n",
      "\n",
      "Test search for: 'diabetes with foot ulcer'\n",
      "\n",
      "1. Code: E13621\n",
      "   Description: Other specified diabetes mellitus with foot ulcer\n",
      "   Chapter: IV. Endocrine, nutritional and metabolic diseases\n",
      "   Distance: 0.0933\n",
      "\n",
      "2. Code: E08621\n",
      "   Description: Diabetes mellitus due to underlying condition with foot ulcer\n",
      "   Chapter: IV. Endocrine, nutritional and metabolic diseases\n",
      "   Distance: 0.0977\n",
      "\n",
      "3. Code: E11621\n",
      "   Description: Type 2 diabetes mellitus with foot ulcer\n",
      "   Chapter: IV. Endocrine, nutritional and metabolic diseases\n",
      "   Distance: 0.1556\n",
      "\n",
      "============================================================\n",
      "VERIFICATION COMPLETE!\n",
      "All artifacts are working correctly.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying artifacts...\")\n",
    "\n",
    "# Load enriched dataset\n",
    "df_loaded = pd.read_pickle(pkl_path)\n",
    "print(f\"Loaded dataset: {len(df_loaded)} rows\")\n",
    "\n",
    "# Load FAISS index\n",
    "index_loaded = faiss.read_index(index_path)\n",
    "print(f\"Loaded FAISS index: {index_loaded.ntotal} vectors\")\n",
    "\n",
    "# Load metadata\n",
    "with open(meta_path, 'r') as f:\n",
    "    metadata_loaded = json.load(f)\n",
    "print(f\"Loaded metadata: version {metadata_loaded['version']}\")\n",
    "\n",
    "# Test search\n",
    "query = \"diabetes with foot ulcer\"\n",
    "query_embedding = model.encode([query])\n",
    "distances, indices = index_loaded.search(query_embedding.astype('float32'), k=3)\n",
    "\n",
    "print(f\"\\nTest search for: '{query}'\")\n",
    "for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "    row = df_loaded.iloc[idx]\n",
    "    print(f\"\\n{i+1}. Code: {row['code']}\")\n",
    "    print(f\"   Description: {row['description']}\")\n",
    "    print(f\"   Chapter: {row['chapter']}\")\n",
    "    print(f\"   Distance: {dist:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION COMPLETE!\")\n",
    "print(\"All artifacts are working correctly.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
